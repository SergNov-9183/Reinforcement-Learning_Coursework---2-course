{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367a353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Agent.agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ecb773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty city was built.\n",
      "Ground was built.\n",
      "Intersections were built.\n",
      "Roads were built.\n",
      "Intersections were finalized.\n",
      " 12%|█████████▌                                                                         | 3/26 [00:00<00:01, 21.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:01<00:00, 15.63it/s]\n",
      "Transition dictionary was built.\n"
     ]
    }
   ],
   "source": [
    "test_agent0 = Agent(map_sample=1, layout_sample=0)\n",
    "compressed = Agent.load_compressed_q_table_from_file('compressed_q_table')\n",
    "test_agent0.extract_q_table(compressed_q_table=compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c133bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=1, axis1=4)\n",
      "DestCoord(axis0=5, axis1=7)\n",
      "self.current_lane = 1\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "Episode 0: sum_reward = 130800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=4, axis1=7)\n",
      "DestCoord(axis0=2, axis1=1)\n",
      "self.current_lane = 2\n",
      "[[             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 1: sum_reward = 142200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=4, axis1=1)\n",
      "DestCoord(axis0=3, axis1=7)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 3\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 2: sum_reward = 125700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=1, axis1=2)\n",
      "DestCoord(axis0=7, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 3: sum_reward = 158800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=3, axis1=7)\n",
      "DestCoord(axis0=3, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 4: sum_reward = 142200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=8, axis1=4)\n",
      "DestCoord(axis0=8, axis1=6)\n",
      "self.current_lane = 1\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 5\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 5: sum_reward = 81000\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=4)\n",
      "DestCoord(axis0=4, axis1=7)\n",
      "self.current_lane = 2\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 6: sum_reward = 106600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=6, axis1=7)\n",
      "DestCoord(axis0=4, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 7: sum_reward = 132200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=4, axis1=7)\n",
      "DestCoord(axis0=1, axis1=5)\n",
      "self.current_lane = 2\n",
      "[[             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 3\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "Episode 8: sum_reward = 114800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=4, axis1=7)\n",
      "DestCoord(axis0=7, axis1=1)\n",
      "self.current_lane = 0\n",
      "[[             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 9: sum_reward = 137700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=1, axis1=4)\n",
      "DestCoord(axis0=8, axis1=2)\n",
      "self.current_lane = 1\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 3\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "Episode 10: sum_reward = 83700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=6, axis1=7)\n",
      "DestCoord(axis0=8, axis1=4)\n",
      "self.current_lane = 2\n",
      "[[             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 11: sum_reward = 109600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=1, axis1=2)\n",
      "DestCoord(axis0=8, axis1=4)\n",
      "self.current_lane = 1\n",
      "[[  R(v[0, 1, 2]|[2, 1, 0]dsb)             X(0023,5)\n",
      "               G()              ]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "Episode 12: sum_reward = 117700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=1, axis1=5)\n",
      "DestCoord(axis0=3, axis1=7)\n",
      "self.current_lane = 1\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 13: sum_reward = 107100\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=1, axis1=6)\n",
      "DestCoord(axis0=6, axis1=7)\n",
      "self.current_lane = 1\n",
      "[[             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "Episode 14: sum_reward = 133300\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=6, axis1=1)\n",
      "DestCoord(axis0=1, axis1=2)\n",
      "self.current_lane = 3\n",
      "[[             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 5\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 15: sum_reward = 95100\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=2)\n",
      "DestCoord(axis0=8, axis1=2)\n",
      "self.current_lane = 1\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 16: sum_reward = 122200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=7, axis1=7)\n",
      "DestCoord(axis0=1, axis1=4)\n",
      "self.current_lane = 3\n",
      "[[             G()                         X(2200,4)\n",
      "     R(h[0, 1, 2]|[1, 0]dsb)    ]\n",
      " [             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 17: sum_reward = 149800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=7, axis1=7)\n",
      "DestCoord(axis0=3, axis1=7)\n",
      "self.current_lane = 3\n",
      "[[             G()                         X(2200,4)\n",
      "     R(h[0, 1, 2]|[1, 0]dsb)    ]\n",
      " [             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 1\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 18: sum_reward = 108200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=1, axis1=6)\n",
      "DestCoord(axis0=1, axis1=2)\n",
      "self.current_lane = 1\n",
      "[[             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 19: sum_reward = 106000\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=5, axis1=7)\n",
      "DestCoord(axis0=3, axis1=7)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2, 3]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 4\n",
      "action = 0\n",
      "Episode 20: sum_reward = 101000\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=8, axis1=4)\n",
      "DestCoord(axis0=4, axis1=7)\n",
      "self.current_lane = 1\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 21: sum_reward = 154800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=5, axis1=1)\n",
      "DestCoord(axis0=2, axis1=1)\n",
      "self.current_lane = 3\n",
      "[[             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 5\n",
      "action = 0\n",
      "action = 4\n",
      "action = 4\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 22: sum_reward = 75500\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=4)\n",
      "DestCoord(axis0=1, axis1=3)\n",
      "self.current_lane = 2\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 23: sum_reward = 125200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=6, axis1=7)\n",
      "DestCoord(axis0=8, axis1=2)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2, 3]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2, 3]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 3\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "Episode 24: sum_reward = 100800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=4)\n",
      "DestCoord(axis0=1, axis1=3)\n",
      "self.current_lane = 1\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 25: sum_reward = 125200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=8, axis1=2)\n",
      "DestCoord(axis0=7, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()                         X(4020,6)\n",
      "  R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 26: sum_reward = 102100\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=8, axis1=5)\n",
      "DestCoord(axis0=8, axis1=6)\n",
      "self.current_lane = 1\n",
      "[[             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 5\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 27: sum_reward = 83500\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=1, axis1=3)\n",
      "DestCoord(axis0=6, axis1=7)\n",
      "self.current_lane = 0\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 28: sum_reward = 127600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=1, axis1=3)\n",
      "DestCoord(axis0=7, axis1=7)\n",
      "self.current_lane = 1\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 29: sum_reward = 122100\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=6, axis1=7)\n",
      "DestCoord(axis0=7, axis1=1)\n",
      "self.current_lane = 0\n",
      "[[             G()                 R(v[0, 1, 2, 3]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2, 3]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 3\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 30: sum_reward = 118700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=3, axis1=1)\n",
      "DestCoord(axis0=1, axis1=3)\n",
      "self.current_lane = 2\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 31: sum_reward = 107100\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=1, axis1=5)\n",
      "DestCoord(axis0=4, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 32: sum_reward = 100600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=5, axis1=7)\n",
      "DestCoord(axis0=1, axis1=3)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 33: sum_reward = 152300\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=4, axis1=7)\n",
      "DestCoord(axis0=1, axis1=5)\n",
      "self.current_lane = 0\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 3\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "Episode 34: sum_reward = 101600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=3, axis1=7)\n",
      "DestCoord(axis0=1, axis1=2)\n",
      "self.current_lane = 0\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 35: sum_reward = 162800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=8, axis1=4)\n",
      "DestCoord(axis0=1, axis1=3)\n",
      "self.current_lane = 1\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 36: sum_reward = 136200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=8, axis1=5)\n",
      "DestCoord(axis0=2, axis1=1)\n",
      "self.current_lane = 0\n",
      "[[             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 37: sum_reward = 130100\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=1, axis1=3)\n",
      "DestCoord(axis0=7, axis1=1)\n",
      "self.current_lane = 0\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 38: sum_reward = 160300\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=3, axis1=1)\n",
      "DestCoord(axis0=4, axis1=7)\n",
      "self.current_lane = 0\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 39: sum_reward = 137700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=3, axis1=1)\n",
      "DestCoord(axis0=3, axis1=7)\n",
      "self.current_lane = 2\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 40: sum_reward = 126200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=8, axis1=2)\n",
      "DestCoord(axis0=1, axis1=6)\n",
      "self.current_lane = 1\n",
      "[[             G()                         X(4020,6)\n",
      "  R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 41: sum_reward = 134700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=4, axis1=7)\n",
      "DestCoord(axis0=5, axis1=7)\n",
      "self.current_lane = 2\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 42: sum_reward = 114700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=1, axis1=5)\n",
      "DestCoord(axis0=6, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 4\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 43: sum_reward = 153800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=1, axis1=4)\n",
      "DestCoord(axis0=1, axis1=5)\n",
      "self.current_lane = 1\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 44: sum_reward = 114700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=4, axis1=1)\n",
      "DestCoord(axis0=1, axis1=3)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 45: sum_reward = 109600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=3, axis1=1)\n",
      "DestCoord(axis0=1, axis1=6)\n",
      "self.current_lane = 2\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 46: sum_reward = 114600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=5, axis1=1)\n",
      "DestCoord(axis0=8, axis1=5)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 47: sum_reward = 154800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=2)\n",
      "DestCoord(axis0=8, axis1=5)\n",
      "self.current_lane = 0\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 48: sum_reward = 107500\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=1, axis1=3)\n",
      "DestCoord(axis0=8, axis1=4)\n",
      "self.current_lane = 0\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 49: sum_reward = 145200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=6, axis1=1)\n",
      "DestCoord(axis0=5, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 5\n",
      "action = 0\n",
      "action = 4\n",
      "action = 4\n",
      "Episode 50: sum_reward = 49500\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=6, axis1=7)\n",
      "DestCoord(axis0=1, axis1=4)\n",
      "self.current_lane = 2\n",
      "[[             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 51: sum_reward = 152300\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=6, axis1=7)\n",
      "DestCoord(axis0=1, axis1=3)\n",
      "self.current_lane = 0\n",
      "[[             G()                 R(v[0, 1, 2, 3]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2, 3]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 3\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 52: sum_reward = 111600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=2, axis1=7)\n",
      "DestCoord(axis0=6, axis1=1)\n",
      "self.current_lane = 2\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 53: sum_reward = 137200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=6)\n",
      "DestCoord(axis0=8, axis1=6)\n",
      "self.current_lane = 1\n",
      "[[  R(v[0, 1, 2, 3]|[1, 0]dsb)             X(2200,4)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 2\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 54: sum_reward = 102200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=4, axis1=7)\n",
      "DestCoord(axis0=1, axis1=6)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 3\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "Episode 55: sum_reward = 96300\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=2, axis1=7)\n",
      "DestCoord(axis0=6, axis1=7)\n",
      "self.current_lane = 0\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 56: sum_reward = 110000\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=1, axis1=4)\n",
      "DestCoord(axis0=8, axis1=3)\n",
      "self.current_lane = 0\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 57: sum_reward = 145200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=2, axis1=1)\n",
      "DestCoord(axis0=7, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 58: sum_reward = 108500\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=3, axis1=7)\n",
      "DestCoord(axis0=3, axis1=7)\n",
      "self.current_lane = 2\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 59: sum_reward = 107200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=1, axis1=4)\n",
      "DestCoord(axis0=1, axis1=4)\n",
      "self.current_lane = 1\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 60: sum_reward = 112200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=6, axis1=1)\n",
      "DestCoord(axis0=8, axis1=2)\n",
      "self.current_lane = 3\n",
      "[[             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 61: sum_reward = -35000\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=2, axis1=1)\n",
      "DestCoord(axis0=1, axis1=4)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "Episode 62: sum_reward = 142300\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=4, axis1=7)\n",
      "DestCoord(axis0=8, axis1=4)\n",
      "self.current_lane = 2\n",
      "[[             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 63: sum_reward = 114600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=8, axis1=6)\n",
      "DestCoord(axis0=1, axis1=4)\n",
      "self.current_lane = 0\n",
      "[[             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 64: sum_reward = 147700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=7, axis1=7)\n",
      "DestCoord(axis0=5, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2, 3]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2, 3]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 65: sum_reward = 120200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=3, axis1=7)\n",
      "DestCoord(axis0=7, axis1=7)\n",
      "self.current_lane = 0\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 66: sum_reward = 125200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=4, axis1=7)\n",
      "DestCoord(axis0=1, axis1=3)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 67: sum_reward = 154800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=8, axis1=2)\n",
      "DestCoord(axis0=2, axis1=7)\n",
      "self.current_lane = 0\n",
      "[[             G()                         X(4020,6)\n",
      "  R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 68: sum_reward = 152800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=4)\n",
      "DestCoord(axis0=5, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 69: sum_reward = 127300\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=1, axis1=5)\n",
      "DestCoord(axis0=7, axis1=1)\n",
      "self.current_lane = 0\n",
      "[[             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 70: sum_reward = 108100\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=3, axis1=1)\n",
      "DestCoord(axis0=1, axis1=4)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 3\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 71: sum_reward = 98600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=7, axis1=1)\n",
      "DestCoord(axis0=7, axis1=7)\n",
      "self.current_lane = 0\n",
      "[[             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 72: sum_reward = 155200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=2, axis1=7)\n",
      "DestCoord(axis0=6, axis1=7)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 73: sum_reward = 106000\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=1, axis1=4)\n",
      "DestCoord(axis0=8, axis1=6)\n",
      "self.current_lane = 0\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 74: sum_reward = 137700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=3, axis1=1)\n",
      "DestCoord(axis0=1, axis1=2)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 75: sum_reward = 104600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=8, axis1=2)\n",
      "DestCoord(axis0=4, axis1=1)\n",
      "self.current_lane = 0\n",
      "[[             G()                         X(4020,6)\n",
      "  R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 76: sum_reward = 117600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=8, axis1=5)\n",
      "DestCoord(axis0=1, axis1=2)\n",
      "self.current_lane = 0\n",
      "[[             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 77: sum_reward = 140200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=5)\n",
      "DestCoord(axis0=8, axis1=6)\n",
      "self.current_lane = 2\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 4\n",
      "Episode 78: sum_reward = 78500\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=2, axis1=7)\n",
      "DestCoord(axis0=1, axis1=4)\n",
      "self.current_lane = 0\n",
      "[[   R(h[0, 1]|[2, 1, 0]dsb)               X(0203,5)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "Episode 79: sum_reward = 103100\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=2, axis1=7)\n",
      "DestCoord(axis0=6, axis1=1)\n",
      "self.current_lane = 0\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 80: sum_reward = 145200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=2, axis1=1)\n",
      "DestCoord(axis0=6, axis1=1)\n",
      "self.current_lane = 0\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 81: sum_reward = 110000\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=5)\n",
      "DestCoord(axis0=7, axis1=7)\n",
      "self.current_lane = 2\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 4\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "Episode 82: sum_reward = 80600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=8, axis1=6)\n",
      "DestCoord(axis0=1, axis1=2)\n",
      "self.current_lane = 0\n",
      "[[             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 83: sum_reward = 142700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=5)\n",
      "DestCoord(axis0=3, axis1=7)\n",
      "self.current_lane = 1\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 84: sum_reward = 110600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=2, axis1=7)\n",
      "DestCoord(axis0=1, axis1=5)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 3\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "Episode 85: sum_reward = 119800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=1, axis1=4)\n",
      "DestCoord(axis0=8, axis1=2)\n",
      "self.current_lane = 1\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 3\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "Episode 86: sum_reward = 83700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=5)\n",
      "DestCoord(axis0=1, axis1=4)\n",
      "self.current_lane = 1\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "Episode 87: sum_reward = 120200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'W'\n",
      "CarCoord(axis0=1, axis1=4)\n",
      "DestCoord(axis0=5, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1, 2]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 88: sum_reward = 100600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=3, axis1=7)\n",
      "DestCoord(axis0=1, axis1=4)\n",
      "self.current_lane = 0\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 3\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "Episode 89: sum_reward = 101600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=4, axis1=7)\n",
      "DestCoord(axis0=1, axis1=3)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 90: sum_reward = 154800\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=2)\n",
      "DestCoord(axis0=3, axis1=7)\n",
      "self.current_lane = 0\n",
      "[[             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                    R(h[0, 1]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 91: sum_reward = 118100\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=5, axis1=7)\n",
      "DestCoord(axis0=1, axis1=4)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2, 3]|[1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "Episode 92: sum_reward = 110600\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=2, axis1=1)\n",
      "DestCoord(axis0=7, axis1=1)\n",
      "self.current_lane = 2\n",
      "[[             G()                         X(0023,5)\n",
      "       R(h[0, 1]|[1, 0]dsb)     ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 5\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 93: sum_reward = 68500\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=5, axis1=1)\n",
      "DestCoord(axis0=3, axis1=1)\n",
      "self.current_lane = 2\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 4\n",
      "action = 4\n",
      "Episode 94: sum_reward = 97000\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=7, axis1=1)\n",
      "DestCoord(axis0=4, axis1=7)\n",
      "self.current_lane = 0\n",
      "[[     R(h[0, 1]|[1, 0]dsb)                X(4020,6)\n",
      "               G()              ]\n",
      " [             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 95: sum_reward = 113700\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=3, axis1=1)\n",
      "DestCoord(axis0=7, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 5\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "Episode 96: sum_reward = 71000\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'N'\n",
      "CarCoord(axis0=4, axis1=7)\n",
      "DestCoord(axis0=2, axis1=1)\n",
      "self.current_lane = 1\n",
      "[[             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                 R(v[0, 1, 2]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 4\n",
      "Episode 97: sum_reward = 101200\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'E'\n",
      "CarCoord(axis0=8, axis1=4)\n",
      "DestCoord(axis0=7, axis1=1)\n",
      "self.current_lane = 2\n",
      "[[             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]\n",
      " [             G()                  R(h[0, 1]|[2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 2\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 2\n",
      "action = 0\n",
      "Episode 98: sum_reward = 127300\n",
      "\n",
      "\n",
      "INITIAL STATE:\n",
      " self.current_direction = 'S'\n",
      "CarCoord(axis0=7, axis1=1)\n",
      "DestCoord(axis0=1, axis1=4)\n",
      "self.current_lane = 0\n",
      "[[     R(h[0, 1]|[1, 0]dsb)                X(4020,6)\n",
      "               G()              ]\n",
      " [             G()               R(v[0, 1, 2, 3]|[3, 2, 1, 0]dsb)\n",
      "               G()              ]]\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 0\n",
      "action = 1\n",
      "action = 0\n",
      "action = 4\n",
      "action = 0\n",
      "Episode 99: sum_reward = 129800\n",
      "\n",
      "\n",
      "99/100 objects reached their destination. Where next_to_border = 92\n"
     ]
    }
   ],
   "source": [
    "test_agent0.perform(n_episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbb728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
